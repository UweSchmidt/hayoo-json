[
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#",
      "description": {
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "module",
        "fct-source": "src/NLP-Tokenize-String.html",
        "fct-type": "module",
        "title": "String"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "String",
        "normalized": "",
        "package": "tokenize",
        "partial": "String",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#t:EitherList",
      "description": {
        "fct-descr": "\u003cp\u003eThe EitherList is a newtype-wrapped list of Eithers.\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "newtype",
        "fct-source": "src/NLP-Tokenize-String.html#EitherList",
        "fct-type": "newtype",
        "title": "EitherList"
      },
      "index": {
        "description": "The EitherList is newtype-wrapped list of Eithers",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "EitherList",
        "normalized": "",
        "package": "tokenize",
        "partial": "Either List",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#t:Tokenizer",
      "description": {
        "fct-descr": "\u003cp\u003eA Tokenizer is function which takes a list and returns a list of Eithers\n  (wrapped in a newtype). Right Strings will be passed on for processing\n  to tokenizers down\n  the pipeline. Left Strings will be passed through the pipeline unchanged.\n  Use a Left String in a tokenizer to protect certain tokens from further \n  processing (e.g. see the \u003ccode\u003e\u003ca\u003euris\u003c/a\u003e\u003c/code\u003e tokenizer).\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "type",
        "fct-source": "src/NLP-Tokenize-String.html#Tokenizer",
        "fct-type": "type",
        "title": "Tokenizer"
      },
      "index": {
        "description": "Tokenizer is function which takes list and returns list of Eithers wrapped in newtype Right Strings will be passed on for processing to tokenizers down the pipeline Left Strings will be passed through the pipeline unchanged Use Left String in tokenizer to protect certain tokens from further processing e.g see the uris tokenizer",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "Tokenizer",
        "normalized": "",
        "package": "tokenize",
        "partial": "Tokenizer",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:E",
      "description": {
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "E",
        "fct-source": "src/NLP-Tokenize-String.html#EitherList",
        "fct-type": "function",
        "title": "E"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "E",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:contractions",
      "description": {
        "fct-descr": "\u003cp\u003eSplit common contractions off and freeze them.\n | Currently deals with: 'm, 's, 'd, 've, 'll\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#contractions",
        "fct-type": "function",
        "title": "contractions"
      },
      "index": {
        "description": "Split common contractions off and freeze them Currently deals with ve ll",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "contractions",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:defaultTokenizer",
      "description": {
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#defaultTokenizer",
        "fct-type": "function",
        "title": "defaultTokenizer"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "defaultTokenizer",
        "normalized": "",
        "package": "tokenize",
        "partial": "Tokenizer",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:finalPunctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off word-final punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#finalPunctuation",
        "fct-type": "function",
        "title": "finalPunctuation"
      },
      "index": {
        "description": "Split off word-final punctuation",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "finalPunctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "Punctuation",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:initialPunctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off word-initial punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#initialPunctuation",
        "fct-type": "function",
        "title": "initialPunctuation"
      },
      "index": {
        "description": "Split off word-initial punctuation",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "initialPunctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "Punctuation",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:negatives",
      "description": {
        "fct-descr": "\u003cp\u003eSplit words ending in n't, and freeze n't \n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#negatives",
        "fct-type": "function",
        "title": "negatives"
      },
      "index": {
        "description": "Split words ending in and freeze",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "negatives",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:punctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off initial and final punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#punctuation",
        "fct-type": "function",
        "title": "punctuation"
      },
      "index": {
        "description": "Split off initial and final punctuation",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "punctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:run",
      "description": {
        "fct-descr": "\u003cp\u003eRun a tokenizer\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer -\u003e String -\u003e [String]",
        "fct-source": "src/NLP-Tokenize-String.html#run",
        "fct-type": "function",
        "title": "run"
      },
      "index": {
        "description": "Run tokenizer",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "run",
        "normalized": "Tokenizer-\u003eString-\u003e[String]",
        "package": "tokenize",
        "partial": "",
        "signature": "Tokenizer-\u003eString-\u003e[String]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:tokenize",
      "description": {
        "fct-descr": "\u003cp\u003eSplit string into words using the default tokenizer pipeline \n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "String -\u003e [String]",
        "fct-source": "src/NLP-Tokenize-String.html#tokenize",
        "fct-type": "function",
        "title": "tokenize"
      },
      "index": {
        "description": "Split string into words using the default tokenizer pipeline",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "tokenize",
        "normalized": "String-\u003e[String]",
        "package": "tokenize",
        "partial": "",
        "signature": "String-\u003e[String]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:unE",
      "description": {
        "fct-descr": "&#160;",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "[Either a b]",
        "fct-source": "src/NLP-Tokenize-String.html#EitherList",
        "fct-type": "function",
        "title": "unE"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "unE",
        "normalized": "[Either a b]",
        "package": "tokenize",
        "partial": "",
        "signature": "[Either a b]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:uris",
      "description": {
        "fct-descr": "\u003cp\u003eDetect common uris and freeze them\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#uris",
        "fct-type": "function",
        "title": "uris"
      },
      "index": {
        "description": "Detect common uris and freeze them",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "uris",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-String.html#v:whitespace",
      "description": {
        "fct-descr": "\u003cp\u003eSplit string on whitespace. This is just a wrapper for Data.List.words\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.String",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-String.html#whitespace",
        "fct-type": "function",
        "title": "whitespace"
      },
      "index": {
        "description": "Split string on whitespace This is just wrapper for Data.List.words",
        "hierarchy": "NLP Tokenize String",
        "module": "NLP.Tokenize.String",
        "name": "whitespace",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#",
      "description": {
        "fct-descr": "\u003cdiv class=\"doc\"\u003e\u003cp\u003eNLP Tokenizer, adapted to use Text instead of Strings from the\n \u003ccode\u003e\u003ca\u003etokenize\u003c/a\u003e\u003c/code\u003e package.\n\u003c/p\u003e\u003c/div\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "module",
        "fct-source": "src/NLP-Tokenize-Text.html",
        "fct-type": "module",
        "title": "Text"
      },
      "index": {
        "description": "NLP Tokenizer adapted to use Text instead of Strings from the tokenize package",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "Text",
        "normalized": "",
        "package": "tokenize",
        "partial": "Text",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#t:EitherList",
      "description": {
        "fct-descr": "\u003cp\u003eThe EitherList is a newtype-wrapped list of Eithers.\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "newtype",
        "fct-source": "src/NLP-Tokenize-Text.html#EitherList",
        "fct-type": "newtype",
        "title": "EitherList"
      },
      "index": {
        "description": "The EitherList is newtype-wrapped list of Eithers",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "EitherList",
        "normalized": "",
        "package": "tokenize",
        "partial": "Either List",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#t:Tokenizer",
      "description": {
        "fct-descr": "\u003cp\u003eA Tokenizer is function which takes a list and returns a list of Eithers\n  (wrapped in a newtype). Right Strings will be passed on for processing\n  to tokenizers down\n  the pipeline. Left Strings will be passed through the pipeline unchanged.\n  Use a Left String in a tokenizer to protect certain tokens from further \n  processing (e.g. see the \u003ccode\u003e\u003ca\u003euris\u003c/a\u003e\u003c/code\u003e tokenizer).\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "type",
        "fct-source": "src/NLP-Tokenize-Text.html#Tokenizer",
        "fct-type": "type",
        "title": "Tokenizer"
      },
      "index": {
        "description": "Tokenizer is function which takes list and returns list of Eithers wrapped in newtype Right Strings will be passed on for processing to tokenizers down the pipeline Left Strings will be passed through the pipeline unchanged Use Left String in tokenizer to protect certain tokens from further processing e.g see the uris tokenizer",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "Tokenizer",
        "normalized": "",
        "package": "tokenize",
        "partial": "Tokenizer",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:E",
      "description": {
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "E",
        "fct-source": "src/NLP-Tokenize-Text.html#EitherList",
        "fct-type": "function",
        "title": "E"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "E",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:contractions",
      "description": {
        "fct-descr": "\u003cp\u003eSplit common contractions off and freeze them.\n | Currently deals with: 'm, 's, 'd, 've, 'll\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#contractions",
        "fct-type": "function",
        "title": "contractions"
      },
      "index": {
        "description": "Split common contractions off and freeze them Currently deals with ve ll",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "contractions",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:defaultTokenizer",
      "description": {
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#defaultTokenizer",
        "fct-type": "function",
        "title": "defaultTokenizer"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "defaultTokenizer",
        "normalized": "",
        "package": "tokenize",
        "partial": "Tokenizer",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:finalPunctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off word-final punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#finalPunctuation",
        "fct-type": "function",
        "title": "finalPunctuation"
      },
      "index": {
        "description": "Split off word-final punctuation",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "finalPunctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "Punctuation",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:initialPunctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off word-initial punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#initialPunctuation",
        "fct-type": "function",
        "title": "initialPunctuation"
      },
      "index": {
        "description": "Split off word-initial punctuation",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "initialPunctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "Punctuation",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:negatives",
      "description": {
        "fct-descr": "\u003cp\u003eSplit words ending in n't, and freeze n't \n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#negatives",
        "fct-type": "function",
        "title": "negatives"
      },
      "index": {
        "description": "Split words ending in and freeze",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "negatives",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:punctuation",
      "description": {
        "fct-descr": "\u003cp\u003eSplit off initial and final punctuation\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#punctuation",
        "fct-type": "function",
        "title": "punctuation"
      },
      "index": {
        "description": "Split off initial and final punctuation",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "punctuation",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:run",
      "description": {
        "fct-descr": "\u003cp\u003eRun a tokenizer\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer -\u003e Text -\u003e [Text]",
        "fct-source": "src/NLP-Tokenize-Text.html#run",
        "fct-type": "function",
        "title": "run"
      },
      "index": {
        "description": "Run tokenizer",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "run",
        "normalized": "Tokenizer-\u003eText-\u003e[Text]",
        "package": "tokenize",
        "partial": "",
        "signature": "Tokenizer-\u003eText-\u003e[Text]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:tokenize",
      "description": {
        "fct-descr": "\u003cp\u003eSplit string into words using the default tokenizer pipeline \n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Text -\u003e [Text]",
        "fct-source": "src/NLP-Tokenize-Text.html#tokenize",
        "fct-type": "function",
        "title": "tokenize"
      },
      "index": {
        "description": "Split string into words using the default tokenizer pipeline",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "tokenize",
        "normalized": "Text-\u003e[Text]",
        "package": "tokenize",
        "partial": "",
        "signature": "Text-\u003e[Text]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:unE",
      "description": {
        "fct-descr": "&#160;",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "[Either a b]",
        "fct-source": "src/NLP-Tokenize-Text.html#EitherList",
        "fct-type": "function",
        "title": "unE"
      },
      "index": {
        "description": "",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "unE",
        "normalized": "[Either a b]",
        "package": "tokenize",
        "partial": "",
        "signature": "[Either a b]"
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:uris",
      "description": {
        "fct-descr": "\u003cp\u003eDetect common uris and freeze them\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#uris",
        "fct-type": "function",
        "title": "uris"
      },
      "index": {
        "description": "Detect common uris and freeze them",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "uris",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize-Text.html#v:whitespace",
      "description": {
        "fct-descr": "\u003cp\u003eSplit string on whitespace. This is just a wrapper for Data.List.words\n\u003c/p\u003e",
        "fct-module": "NLP.Tokenize.Text",
        "fct-package": "tokenize",
        "fct-signature": "Tokenizer",
        "fct-source": "src/NLP-Tokenize-Text.html#whitespace",
        "fct-type": "function",
        "title": "whitespace"
      },
      "index": {
        "description": "Split string on whitespace This is just wrapper for Data.List.words",
        "hierarchy": "NLP Tokenize Text",
        "module": "NLP.Tokenize.Text",
        "name": "whitespace",
        "normalized": "",
        "package": "tokenize",
        "partial": "",
        "signature": ""
      }
    }
  },
  {
    "cmd": "update",
    "document": {
      "uri": "http://hackage.haskell.org/package/tokenize/docs/NLP-Tokenize.html#",
      "description": {
        "fct-descr": "\u003cdiv class=\"doc\"\u003e\u003cp\u003eNLP Tokenizer\n\u003c/p\u003e\u003c/div\u003e",
        "fct-module": "NLP.Tokenize",
        "fct-package": "tokenize",
        "fct-signature": "module",
        "fct-source": "src/NLP-Tokenize.html",
        "fct-type": "module",
        "title": "Tokenize"
      },
      "index": {
        "description": "NLP Tokenizer",
        "hierarchy": "NLP Tokenize",
        "module": "NLP.Tokenize",
        "name": "Tokenize",
        "normalized": "",
        "package": "tokenize",
        "partial": "Tokenize",
        "signature": ""
      }
    }
  }
]